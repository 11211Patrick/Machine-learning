{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# **Homework 1: COVID-19 Cases Prediction (Regression)**","metadata":{"id":"guE34D3Fj2R9","execution":{"iopub.status.busy":"2023-03-01T15:56:54.971241Z","iopub.execute_input":"2023-03-01T15:56:54.971628Z","iopub.status.idle":"2023-03-01T15:56:54.976821Z","shell.execute_reply.started":"2023-03-01T15:56:54.971596Z","shell.execute_reply":"2023-03-01T15:56:54.975738Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"markdown","source":"Objectives:\n* Solve a regression problem with deep neural networks (DNN).\n* Understand basic DNN training tips.\n* Familiarize yourself with PyTorch.\n\nIf you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com","metadata":{"id":"V57zhcTp1Xxb"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"GUATI4ONArv_","execution":{"iopub.status.busy":"2023-03-01T15:56:54.997530Z","iopub.execute_input":"2023-03-01T15:56:54.997824Z","iopub.status.idle":"2023-03-01T15:56:56.023198Z","shell.execute_reply.started":"2023-03-01T15:56:54.997798Z","shell.execute_reply":"2023-03-01T15:56:56.021752Z"},"trusted":true},"execution_count":182,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nWed Mar  1 15:56:55 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   36C    P0    33W / 250W |    821MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Download data\nIf the Google Drive links below do not work, you can use the dropbox link below or download data from [Kaggle](https://www.kaggle.com/t/a339b77fa5214978bfb8dde62d3151fe), and upload data manually to the workspace.","metadata":{"id":"Tm2aXcb-j9Fc"}},{"cell_type":"code","source":"# google drive link\n# !pip install gdown\n# !gdown --id '1BjXalPZxq9mybPKNjF3h5L3NcF7XKTS-' --output covid_train.csv\n# !gdown --id '1B55t74Jg2E5FCsKCsUEkPKIuqaY7UIi1' --output covid_test.csv\n\n# dropbox link\n!wget -O covid_train.csv https://www.dropbox.com/s/lmy1riadzoy0ahw/covid.train.csv?dl=0\n!wget -O covid_test.csv https://www.dropbox.com/s/zalbw42lu4nmhr2/covid.test.csv?dl=0","metadata":{"id":"YPmfl-awlKZA","execution":{"iopub.status.busy":"2023-03-01T15:56:56.028329Z","iopub.execute_input":"2023-03-01T15:56:56.028647Z","iopub.status.idle":"2023-03-01T15:57:01.596322Z","shell.execute_reply.started":"2023-03-01T15:56:56.028616Z","shell.execute_reply":"2023-03-01T15:57:01.595238Z"},"trusted":true},"execution_count":183,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n--2023-03-01 15:56:56--  https://www.dropbox.com/s/lmy1riadzoy0ahw/covid.train.csv?dl=0\nResolving www.dropbox.com (www.dropbox.com)... 162.125.9.18, 2620:100:601f:18::a27d:912\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.9.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: /s/raw/lmy1riadzoy0ahw/covid.train.csv [following]\n--2023-03-01 15:56:57--  https://www.dropbox.com/s/raw/lmy1riadzoy0ahw/covid.train.csv\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://uc39aa0e453ac64e039ea25e6bc6.dl.dropboxusercontent.com/cd/0/inline/B3ZdTWbqp8QMjWw0p509YEnApxU5CBWX5Ngxbz_JT0AjXfmmALkwz-DNzZgbXiJq_0JF1lBFLqVLDKcH7_arD56qBO0mrW9sSzXm58oKmlS1xVmtBKhafiMu_D7UA-9ANJOLyR48Ximu7AZryLYsrOWD_b76ybJgXj9eF7On1H-kuw/file# [following]\n--2023-03-01 15:56:57--  https://uc39aa0e453ac64e039ea25e6bc6.dl.dropboxusercontent.com/cd/0/inline/B3ZdTWbqp8QMjWw0p509YEnApxU5CBWX5Ngxbz_JT0AjXfmmALkwz-DNzZgbXiJq_0JF1lBFLqVLDKcH7_arD56qBO0mrW9sSzXm58oKmlS1xVmtBKhafiMu_D7UA-9ANJOLyR48Ximu7AZryLYsrOWD_b76ybJgXj9eF7On1H-kuw/file\nResolving uc39aa0e453ac64e039ea25e6bc6.dl.dropboxusercontent.com (uc39aa0e453ac64e039ea25e6bc6.dl.dropboxusercontent.com)... 162.125.9.15, 2620:100:601f:15::a27d:90f\nConnecting to uc39aa0e453ac64e039ea25e6bc6.dl.dropboxusercontent.com (uc39aa0e453ac64e039ea25e6bc6.dl.dropboxusercontent.com)|162.125.9.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2162766 (2.1M) [text/plain]\nSaving to: ‘covid_train.csv’\n\ncovid_train.csv     100%[===================>]   2.06M  4.70MB/s    in 0.4s    \n\n2023-03-01 15:56:58 (4.70 MB/s) - ‘covid_train.csv’ saved [2162766/2162766]\n\n/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n--2023-03-01 15:56:59--  https://www.dropbox.com/s/zalbw42lu4nmhr2/covid.test.csv?dl=0\nResolving www.dropbox.com (www.dropbox.com)... 162.125.9.18, 2620:100:601f:18::a27d:912\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.9.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: /s/raw/zalbw42lu4nmhr2/covid.test.csv [following]\n--2023-03-01 15:57:00--  https://www.dropbox.com/s/raw/zalbw42lu4nmhr2/covid.test.csv\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://uca3c788ea47b9eddd72fbf66ffe.dl.dropboxusercontent.com/cd/0/inline/B3aM5mVIQfs6OUnR4xsocnfC16JBE6EpMuqzVfk3yElkW8nLij95BOQ5FKHKkQocx0hze8Rup2oI8MXGy2P95F-vGxKqozfuFZWelszD3X_HfrCLqwrByrrov6vKZ7mUMrft_YV7hOT5KgaTrb_3H3tkVdWIk5rFtLi0aBGy-eZfxw/file# [following]\n--2023-03-01 15:57:00--  https://uca3c788ea47b9eddd72fbf66ffe.dl.dropboxusercontent.com/cd/0/inline/B3aM5mVIQfs6OUnR4xsocnfC16JBE6EpMuqzVfk3yElkW8nLij95BOQ5FKHKkQocx0hze8Rup2oI8MXGy2P95F-vGxKqozfuFZWelszD3X_HfrCLqwrByrrov6vKZ7mUMrft_YV7hOT5KgaTrb_3H3tkVdWIk5rFtLi0aBGy-eZfxw/file\nResolving uca3c788ea47b9eddd72fbf66ffe.dl.dropboxusercontent.com (uca3c788ea47b9eddd72fbf66ffe.dl.dropboxusercontent.com)... 162.125.9.15, 2620:100:601f:15::a27d:90f\nConnecting to uca3c788ea47b9eddd72fbf66ffe.dl.dropboxusercontent.com (uca3c788ea47b9eddd72fbf66ffe.dl.dropboxusercontent.com)|162.125.9.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 638359 (623K) [text/plain]\nSaving to: ‘covid_test.csv’\n\ncovid_test.csv      100%[===================>] 623.40K  1.77MB/s    in 0.3s    \n\n2023-03-01 15:57:01 (1.77 MB/s) - ‘covid_test.csv’ saved [638359/638359]\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import packages","metadata":{"id":"igqIMEgu64-F"}},{"cell_type":"code","source":"# Numerical Operations\nimport math\nimport numpy as np\n\n# Reading/Writing Data\nimport pandas as pd\nimport os\nimport csv\n\n# For Progress Bar\nfrom tqdm import tqdm\n\n# Pytorch\nimport torch \nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\n# For plotting learning curve\nfrom torch.utils.tensorboard import SummaryWriter","metadata":{"id":"xybQNYCXYu13","execution":{"iopub.status.busy":"2023-03-01T15:57:01.598413Z","iopub.execute_input":"2023-03-01T15:57:01.598806Z","iopub.status.idle":"2023-03-01T15:57:01.606942Z","shell.execute_reply.started":"2023-03-01T15:57:01.598764Z","shell.execute_reply":"2023-03-01T15:57:01.605987Z"},"trusted":true},"execution_count":184,"outputs":[]},{"cell_type":"markdown","source":"# Some Utility Functions\n\nYou do not need to modify this part.","metadata":{"id":"fTAVqRfc2KK3"}},{"cell_type":"code","source":"def same_seed(seed): \n    '''Fixes random number generator seeds for reproducibility.'''\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\ndef train_valid_split(data_set, valid_ratio, seed):\n    '''Split provided training data into training set and validation set'''\n    valid_set_size = int(valid_ratio * len(data_set)) \n    train_set_size = len(data_set) - valid_set_size\n    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n    return np.array(train_set), np.array(valid_set)\n\ndef predict(test_loader, model, device):\n    model.eval() # Set your model to evaluation mode.\n    preds = []\n    for x in tqdm(test_loader):\n        x = x.to(device)                        \n        with torch.no_grad():                   \n            pred = model(x)                     \n            preds.append(pred.detach().cpu())   \n    preds = torch.cat(preds, dim=0).numpy()  \n    return preds","metadata":{"id":"RbrcpfYN2I-H","execution":{"iopub.status.busy":"2023-03-01T15:57:01.609835Z","iopub.execute_input":"2023-03-01T15:57:01.610977Z","iopub.status.idle":"2023-03-01T15:57:01.622466Z","shell.execute_reply.started":"2023-03-01T15:57:01.610942Z","shell.execute_reply":"2023-03-01T15:57:01.621528Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"IqO3lTm78nNO"}},{"cell_type":"code","source":"class COVID19Dataset(Dataset):\n    '''\n    x: Features.\n    y: Targets, if none, do prediction.\n    '''\n    def __init__(self, x, y=None):\n        if y is None:\n            self.y = y\n        else:\n            self.y = torch.FloatTensor(y)\n        self.x = torch.FloatTensor(x)\n\n    def __getitem__(self, idx):\n        if self.y is None:\n            return self.x[idx]\n        else:\n            return self.x[idx], self.y[idx]\n\n    def __len__(self):\n        return len(self.x)","metadata":{"id":"-mjaJM0wprMs","execution":{"iopub.status.busy":"2023-03-01T15:57:01.623973Z","iopub.execute_input":"2023-03-01T15:57:01.624478Z","iopub.status.idle":"2023-03-01T15:57:01.636651Z","shell.execute_reply.started":"2023-03-01T15:57:01.624444Z","shell.execute_reply":"2023-03-01T15:57:01.635684Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"markdown","source":"# Neural Network Model\nTry out different model architectures by modifying the class below.","metadata":{"id":"m73ooU75CL_j"}},{"cell_type":"code","source":"class My_Model(nn.Module):\n    def __init__(self, input_dim):\n        super(My_Model, self).__init__()\n        # TODO: modify model's structure, be aware of dimensions. \n        self.layers = nn.Sequential(\n            nn.Linear(input_dim, 16),\n            nn.ReLU(),\n            \n            \n            nn.Linear(16, 8),\n            nn.ReLU(),\n            nn.Linear(8, 1)\n        )\n\n    def forward(self, x):\n        x = self.layers(x)\n        x = x.squeeze(1) # (B, 1) -> (B)\n        return x","metadata":{"id":"Qn97_WvvrEkG","execution":{"iopub.status.busy":"2023-03-01T15:57:01.638231Z","iopub.execute_input":"2023-03-01T15:57:01.638942Z","iopub.status.idle":"2023-03-01T15:57:01.649218Z","shell.execute_reply.started":"2023-03-01T15:57:01.638908Z","shell.execute_reply":"2023-03-01T15:57:01.648362Z"},"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection\nChoose features you deem useful by modifying the function below.","metadata":{"id":"x5-LKF6R8xeq"}},{"cell_type":"code","source":"def select_feat(train_data, valid_data, test_data, select_all=False):\n    '''Selects useful features to perform regression'''\n    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n\n    if select_all:\n        feat_idx = list(range(raw_x_train.shape[1]))\n    else:\n        feat_idx = [34,35,36,46,47,51,52,53,54,64,65,69,70,71,72,82,83]  # TODO: Select suitable feature columns.\n        \n    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid","metadata":{"id":"0FEnKRaIIeKp","execution":{"iopub.status.busy":"2023-03-01T15:57:01.650965Z","iopub.execute_input":"2023-03-01T15:57:01.651753Z","iopub.status.idle":"2023-03-01T15:57:01.663907Z","shell.execute_reply.started":"2023-03-01T15:57:01.651718Z","shell.execute_reply":"2023-03-01T15:57:01.662912Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"# Training Loop","metadata":{"id":"kADIPNQ2Ih5X","execution":{"iopub.status.busy":"2023-03-01T15:57:01.665413Z","iopub.execute_input":"2023-03-01T15:57:01.666175Z","iopub.status.idle":"2023-03-01T15:57:01.673587Z","shell.execute_reply.started":"2023-03-01T15:57:01.666142Z","shell.execute_reply":"2023-03-01T15:57:01.672516Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"markdown","source":"# Configurations\n`config` contains hyper-parameters for training and the path to save your model.","metadata":{"id":"0pgkOh2e9UjE"}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nconfig = {\n    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n    'select_all': False,   # Whether to use all features.\n    'valid_ratio': 0.05,   # validation_size = train_size * valid_ratio\n    'n_epochs': 20000,     # Number of epochs.            \n    'batch_size': 300, \n    'learning_rate':1e-3,              \n    'early_stop': 600,    # If model has not improved for this many consecutive epochs, stop training.     \n    'save_path': './models/model.ckpt'  # Your model will be saved here.\n}","metadata":{"id":"QoWPUahCtoT6","execution":{"iopub.status.busy":"2023-03-01T15:57:01.675270Z","iopub.execute_input":"2023-03-01T15:57:01.676118Z","iopub.status.idle":"2023-03-01T15:57:01.683555Z","shell.execute_reply.started":"2023-03-01T15:57:01.676082Z","shell.execute_reply":"2023-03-01T15:57:01.682589Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader\nRead data from files and set up training, validation, and testing sets. You do not need to modify this part.","metadata":{"id":"lrS-aJJh9XkW"}},{"cell_type":"code","source":"def trainer(train_loader, valid_loader, model, config, device):\n\n    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n\n    # Define your optimization algorithm. \n    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n    # optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9, weight_decay=0.05) \n    optimizer = torch.optim.Adam(model.parameters(),lr=config['learning_rate'],betas=(0.9,0.99), weight_decay=0.2, amsgrad=True)\n    writer = SummaryWriter() # Writer of tensoboard.\n\n    if not os.path.isdir('./models'):\n        os.mkdir('./models') # Create directory of saving models.\n\n    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n\n    for epoch in range(n_epochs):\n        model.train() # Set your model to train mode.\n        loss_record = []\n\n        # tqdm is a package to visualize your training progress.\n      # train_pbar = tqdm(train_loader, position=0, leave=True)\n\n        for x, y in train_loader:\n            optimizer.zero_grad()               # Set gradient to zero.\n            x, y = x.to(device), y.to(device)   # Move your data to device. \n            pred = model(x)             \n            loss = criterion(pred, y)\n            loss.backward()                     # Compute gradient(backpropagation).\n            optimizer.step()                    # Update parameters.\n            step += 1\n            loss_record.append(loss.detach().item())\n            \n            # Display current epoch number and loss on tqdm progress bar.\n            #train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n            #train_pbar.set_postfix({'loss': loss.detach().item()})\n\n        mean_train_loss = sum(loss_record)/len(loss_record)\n        writer.add_scalar('Loss/train', mean_train_loss, step)\n\n        model.eval() # Set your model to evaluation mode.\n        loss_record = []\n        for x, y in valid_loader:\n            x, y = x.to(device), y.to(device)\n            with torch.no_grad():\n                pred = model(x)\n                loss = criterion(pred, y)\n\n            loss_record.append(loss.item())\n            \n        mean_valid_loss = sum(loss_record)/len(loss_record)\n        #print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n        # writer.add_scalar('Loss/valid', mean_valid_loss, step)\n\n        if mean_valid_loss < best_loss:\n            best_loss = mean_valid_loss\n            torch.save(model.state_dict(), config['save_path']) # Save your best model\n            print('Saving model with loss {:.3f}...'.format(best_loss))\n            print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n            early_stop_count = 0\n        else: \n            early_stop_count += 1\n\n        if early_stop_count >= config['early_stop']:\n            print('\\nModel is not improving, so we halt the training session.')\n            print('Saving model with loss {:.3f}...'.format(best_loss))\n            return","metadata":{"id":"k4Rq8_TztAhq","execution":{"iopub.status.busy":"2023-03-01T15:57:01.687385Z","iopub.execute_input":"2023-03-01T15:57:01.688224Z","iopub.status.idle":"2023-03-01T15:57:01.702590Z","shell.execute_reply.started":"2023-03-01T15:57:01.688133Z","shell.execute_reply":"2023-03-01T15:57:01.701684Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"# Set seed for reproducibility\nsame_seed(config['seed'])\n\n\n# train_data size: 3009 x 89 (35 states + 18 features x 3 days) \n# test_data size: 997 x 88 (without last day's positive rate)\ntrain_data, test_data = pd.read_csv('./covid_train.csv').values, pd.read_csv('./covid_test.csv').values\ntrain_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n\n# Print out the data size.\nprint(f\"\"\"train_data size: {train_data.shape} \nvalid_data size: {valid_data.shape} \ntest_data size: {test_data.shape}\"\"\")\n\n# Select features\nx_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config['select_all'])\n\n# Print out the number of features.\nprint(f'number of features: {x_train.shape[1]}')\n\ntrain_dataset, valid_dataset, test_dataset = COVID19Dataset(x_train, y_train), \\\n                                            COVID19Dataset(x_valid, y_valid), \\\n                                            COVID19Dataset(x_test)\n\n# Pytorch data loader loads pytorch dataset into batches.\ntrain_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)","metadata":{"id":"2jc7ZfDot2t9","execution":{"iopub.status.busy":"2023-03-01T15:57:01.703900Z","iopub.execute_input":"2023-03-01T15:57:01.704822Z","iopub.status.idle":"2023-03-01T15:57:01.774752Z","shell.execute_reply.started":"2023-03-01T15:57:01.704743Z","shell.execute_reply":"2023-03-01T15:57:01.773780Z"},"trusted":true},"execution_count":192,"outputs":[{"name":"stdout","text":"train_data size: (2859, 89) \nvalid_data size: (150, 89) \ntest_data size: (997, 88)\nnumber of features: 17\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Start training!","metadata":{"id":"0OBYgjCA-YwD"}},{"cell_type":"code","source":"model = My_Model(input_dim=x_train.shape[1]).to(device) # put your model and data on the same computation device.\ntrainer(train_loader, valid_loader, model, config, device)","metadata":{"id":"YdttVRkAfu2t","execution":{"iopub.status.busy":"2023-03-01T15:57:01.776387Z","iopub.execute_input":"2023-03-01T15:57:01.777074Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Saving model with loss 334.226...\nEpoch [1/10000]: Train loss: 293.1008, Valid loss: 334.2261\nSaving model with loss 270.041...\nEpoch [2/10000]: Train loss: 230.5460, Valid loss: 270.0410\nSaving model with loss 208.960...\nEpoch [3/10000]: Train loss: 184.1867, Valid loss: 208.9601\nSaving model with loss 153.609...\nEpoch [4/10000]: Train loss: 134.6830, Valid loss: 153.6087\nSaving model with loss 105.441...\nEpoch [5/10000]: Train loss: 95.8321, Valid loss: 105.4406\nSaving model with loss 70.526...\nEpoch [6/10000]: Train loss: 62.5736, Valid loss: 70.5265\nSaving model with loss 52.624...\nEpoch [7/10000]: Train loss: 44.8884, Valid loss: 52.6242\nSaving model with loss 46.866...\nEpoch [8/10000]: Train loss: 39.0264, Valid loss: 46.8664\nSaving model with loss 45.046...\nEpoch [9/10000]: Train loss: 39.0540, Valid loss: 45.0459\nSaving model with loss 43.742...\nEpoch [10/10000]: Train loss: 38.2285, Valid loss: 43.7421\nSaving model with loss 42.752...\nEpoch [11/10000]: Train loss: 37.6694, Valid loss: 42.7520\nSaving model with loss 42.013...\nEpoch [12/10000]: Train loss: 35.4602, Valid loss: 42.0133\nSaving model with loss 40.862...\nEpoch [13/10000]: Train loss: 33.5908, Valid loss: 40.8618\nSaving model with loss 39.389...\nEpoch [14/10000]: Train loss: 31.8893, Valid loss: 39.3888\nSaving model with loss 37.306...\nEpoch [15/10000]: Train loss: 31.0168, Valid loss: 37.3058\nSaving model with loss 35.150...\nEpoch [16/10000]: Train loss: 29.5294, Valid loss: 35.1503\nSaving model with loss 33.315...\nEpoch [17/10000]: Train loss: 28.2570, Valid loss: 33.3147\nSaving model with loss 31.177...\nEpoch [18/10000]: Train loss: 25.8649, Valid loss: 31.1770\nSaving model with loss 29.339...\nEpoch [19/10000]: Train loss: 24.3389, Valid loss: 29.3395\nSaving model with loss 27.729...\nEpoch [20/10000]: Train loss: 22.8916, Valid loss: 27.7290\nSaving model with loss 25.935...\nEpoch [21/10000]: Train loss: 22.1505, Valid loss: 25.9347\nSaving model with loss 24.038...\nEpoch [22/10000]: Train loss: 20.3832, Valid loss: 24.0380\nSaving model with loss 22.308...\nEpoch [23/10000]: Train loss: 18.5678, Valid loss: 22.3077\nSaving model with loss 20.676...\nEpoch [24/10000]: Train loss: 17.4409, Valid loss: 20.6764\nSaving model with loss 19.028...\nEpoch [25/10000]: Train loss: 15.9523, Valid loss: 19.0277\nSaving model with loss 17.356...\nEpoch [26/10000]: Train loss: 14.8125, Valid loss: 17.3562\nSaving model with loss 15.982...\nEpoch [27/10000]: Train loss: 13.3099, Valid loss: 15.9823\nSaving model with loss 14.491...\nEpoch [28/10000]: Train loss: 12.5603, Valid loss: 14.4914\nSaving model with loss 12.939...\nEpoch [29/10000]: Train loss: 10.9900, Valid loss: 12.9392\nSaving model with loss 11.675...\nEpoch [30/10000]: Train loss: 9.9509, Valid loss: 11.6755\nSaving model with loss 10.644...\nEpoch [31/10000]: Train loss: 8.9504, Valid loss: 10.6437\nSaving model with loss 9.620...\nEpoch [32/10000]: Train loss: 8.0365, Valid loss: 9.6199\nSaving model with loss 8.870...\nEpoch [33/10000]: Train loss: 7.1728, Valid loss: 8.8699\nSaving model with loss 8.247...\nEpoch [34/10000]: Train loss: 6.7670, Valid loss: 8.2467\nSaving model with loss 7.776...\nEpoch [35/10000]: Train loss: 6.2844, Valid loss: 7.7758\nSaving model with loss 7.382...\nEpoch [36/10000]: Train loss: 5.9903, Valid loss: 7.3821\nSaving model with loss 7.071...\nEpoch [37/10000]: Train loss: 5.5054, Valid loss: 7.0715\nSaving model with loss 6.818...\nEpoch [38/10000]: Train loss: 5.3650, Valid loss: 6.8181\nSaving model with loss 6.609...\nEpoch [39/10000]: Train loss: 5.2488, Valid loss: 6.6094\nSaving model with loss 6.433...\nEpoch [40/10000]: Train loss: 5.0814, Valid loss: 6.4333\nSaving model with loss 6.253...\nEpoch [41/10000]: Train loss: 5.0679, Valid loss: 6.2525\nSaving model with loss 6.107...\nEpoch [42/10000]: Train loss: 4.8785, Valid loss: 6.1074\nSaving model with loss 5.982...\nEpoch [43/10000]: Train loss: 4.7122, Valid loss: 5.9818\nSaving model with loss 5.855...\nEpoch [44/10000]: Train loss: 4.6450, Valid loss: 5.8546\nSaving model with loss 5.724...\nEpoch [45/10000]: Train loss: 4.6062, Valid loss: 5.7239\nSaving model with loss 5.601...\nEpoch [46/10000]: Train loss: 4.4498, Valid loss: 5.6008\nSaving model with loss 5.497...\nEpoch [47/10000]: Train loss: 4.4052, Valid loss: 5.4974\nSaving model with loss 5.379...\nEpoch [48/10000]: Train loss: 4.5072, Valid loss: 5.3795\nSaving model with loss 5.271...\nEpoch [49/10000]: Train loss: 4.1581, Valid loss: 5.2709\nSaving model with loss 5.173...\nEpoch [50/10000]: Train loss: 4.2211, Valid loss: 5.1727\nSaving model with loss 5.062...\nEpoch [51/10000]: Train loss: 4.0464, Valid loss: 5.0624\nSaving model with loss 4.964...\nEpoch [52/10000]: Train loss: 4.1381, Valid loss: 4.9642\nSaving model with loss 4.869...\nEpoch [53/10000]: Train loss: 4.1076, Valid loss: 4.8686\nSaving model with loss 4.765...\nEpoch [54/10000]: Train loss: 3.8862, Valid loss: 4.7645\nSaving model with loss 4.672...\nEpoch [55/10000]: Train loss: 3.8249, Valid loss: 4.6716\nSaving model with loss 4.569...\nEpoch [56/10000]: Train loss: 3.7934, Valid loss: 4.5691\nSaving model with loss 4.471...\nEpoch [57/10000]: Train loss: 3.7038, Valid loss: 4.4711\nSaving model with loss 4.378...\nEpoch [58/10000]: Train loss: 3.7226, Valid loss: 4.3777\nSaving model with loss 4.291...\nEpoch [59/10000]: Train loss: 3.5807, Valid loss: 4.2907\nSaving model with loss 4.206...\nEpoch [60/10000]: Train loss: 3.5457, Valid loss: 4.2057\nSaving model with loss 4.117...\nEpoch [61/10000]: Train loss: 3.3912, Valid loss: 4.1173\nSaving model with loss 4.035...\nEpoch [62/10000]: Train loss: 3.3093, Valid loss: 4.0348\nSaving model with loss 3.952...\nEpoch [63/10000]: Train loss: 3.2762, Valid loss: 3.9518\nSaving model with loss 3.870...\nEpoch [64/10000]: Train loss: 3.2158, Valid loss: 3.8701\nSaving model with loss 3.791...\nEpoch [65/10000]: Train loss: 3.1775, Valid loss: 3.7911\nSaving model with loss 3.712...\nEpoch [66/10000]: Train loss: 3.2081, Valid loss: 3.7121\nSaving model with loss 3.638...\nEpoch [67/10000]: Train loss: 3.2276, Valid loss: 3.6377\nSaving model with loss 3.548...\nEpoch [68/10000]: Train loss: 3.1873, Valid loss: 3.5485\nSaving model with loss 3.482...\nEpoch [69/10000]: Train loss: 3.0463, Valid loss: 3.4824\nSaving model with loss 3.398...\nEpoch [70/10000]: Train loss: 2.9284, Valid loss: 3.3984\nSaving model with loss 3.348...\nEpoch [71/10000]: Train loss: 2.8677, Valid loss: 3.3480\nSaving model with loss 3.256...\nEpoch [72/10000]: Train loss: 2.9666, Valid loss: 3.2561\nSaving model with loss 3.191...\nEpoch [73/10000]: Train loss: 2.7241, Valid loss: 3.1906\nSaving model with loss 3.116...\nEpoch [74/10000]: Train loss: 2.7135, Valid loss: 3.1159\nSaving model with loss 3.044...\nEpoch [75/10000]: Train loss: 2.6608, Valid loss: 3.0442\nSaving model with loss 2.984...\nEpoch [76/10000]: Train loss: 2.6242, Valid loss: 2.9843\nSaving model with loss 2.913...\nEpoch [77/10000]: Train loss: 2.5469, Valid loss: 2.9131\nSaving model with loss 2.852...\nEpoch [78/10000]: Train loss: 2.4906, Valid loss: 2.8524\nSaving model with loss 2.801...\nEpoch [79/10000]: Train loss: 2.4555, Valid loss: 2.8010\nSaving model with loss 2.741...\nEpoch [80/10000]: Train loss: 2.4254, Valid loss: 2.7406\nSaving model with loss 2.682...\nEpoch [81/10000]: Train loss: 2.3933, Valid loss: 2.6822\nSaving model with loss 2.627...\nEpoch [82/10000]: Train loss: 2.3092, Valid loss: 2.6275\nSaving model with loss 2.575...\nEpoch [83/10000]: Train loss: 2.3280, Valid loss: 2.5746\nSaving model with loss 2.520...\nEpoch [84/10000]: Train loss: 2.1967, Valid loss: 2.5199\nSaving model with loss 2.465...\nEpoch [85/10000]: Train loss: 2.2231, Valid loss: 2.4655\nSaving model with loss 2.419...\nEpoch [86/10000]: Train loss: 2.1264, Valid loss: 2.4188\nSaving model with loss 2.365...\nEpoch [87/10000]: Train loss: 2.1339, Valid loss: 2.3647\nSaving model with loss 2.317...\nEpoch [88/10000]: Train loss: 2.0933, Valid loss: 2.3171\nSaving model with loss 2.263...\nEpoch [89/10000]: Train loss: 2.1349, Valid loss: 2.2627\nSaving model with loss 2.218...\nEpoch [90/10000]: Train loss: 2.0669, Valid loss: 2.2181\nSaving model with loss 2.173...\nEpoch [91/10000]: Train loss: 2.0543, Valid loss: 2.1734\nSaving model with loss 2.128...\nEpoch [92/10000]: Train loss: 1.9259, Valid loss: 2.1276\nSaving model with loss 2.090...\nEpoch [93/10000]: Train loss: 1.9689, Valid loss: 2.0895\nSaving model with loss 2.044...\nEpoch [94/10000]: Train loss: 1.9609, Valid loss: 2.0437\nSaving model with loss 2.006...\nEpoch [95/10000]: Train loss: 1.8786, Valid loss: 2.0062\nSaving model with loss 1.969...\nEpoch [96/10000]: Train loss: 1.7789, Valid loss: 1.9687\nSaving model with loss 1.925...\nEpoch [97/10000]: Train loss: 1.7755, Valid loss: 1.9254\nSaving model with loss 1.890...\nEpoch [98/10000]: Train loss: 1.8042, Valid loss: 1.8903\nSaving model with loss 1.853...\nEpoch [99/10000]: Train loss: 1.7568, Valid loss: 1.8534\nSaving model with loss 1.815...\nEpoch [100/10000]: Train loss: 1.7475, Valid loss: 1.8149\nSaving model with loss 1.782...\nEpoch [101/10000]: Train loss: 1.7023, Valid loss: 1.7824\nSaving model with loss 1.748...\nEpoch [102/10000]: Train loss: 1.6261, Valid loss: 1.7481\nSaving model with loss 1.715...\nEpoch [103/10000]: Train loss: 1.6799, Valid loss: 1.7151\nSaving model with loss 1.692...\nEpoch [104/10000]: Train loss: 1.5857, Valid loss: 1.6923\nSaving model with loss 1.656...\nEpoch [105/10000]: Train loss: 1.5733, Valid loss: 1.6558\nSaving model with loss 1.624...\nEpoch [106/10000]: Train loss: 1.5278, Valid loss: 1.6236\nSaving model with loss 1.593...\nEpoch [107/10000]: Train loss: 1.6039, Valid loss: 1.5932\nSaving model with loss 1.569...\nEpoch [108/10000]: Train loss: 1.5398, Valid loss: 1.5691\nSaving model with loss 1.549...\nEpoch [109/10000]: Train loss: 1.5343, Valid loss: 1.5490\nSaving model with loss 1.522...\nEpoch [110/10000]: Train loss: 1.4822, Valid loss: 1.5224\nSaving model with loss 1.504...\nEpoch [111/10000]: Train loss: 1.4398, Valid loss: 1.5040\nSaving model with loss 1.497...\nEpoch [112/10000]: Train loss: 1.3988, Valid loss: 1.4966\nSaving model with loss 1.491...\nEpoch [113/10000]: Train loss: 1.4085, Valid loss: 1.4905\nSaving model with loss 1.453...\nEpoch [114/10000]: Train loss: 1.4175, Valid loss: 1.4529\nSaving model with loss 1.438...\nEpoch [115/10000]: Train loss: 1.4188, Valid loss: 1.4377\nSaving model with loss 1.426...\nEpoch [116/10000]: Train loss: 1.4124, Valid loss: 1.4261\nSaving model with loss 1.403...\nEpoch [119/10000]: Train loss: 1.3974, Valid loss: 1.4029\nSaving model with loss 1.398...\nEpoch [120/10000]: Train loss: 1.3608, Valid loss: 1.3977\nSaving model with loss 1.376...\nEpoch [123/10000]: Train loss: 1.4085, Valid loss: 1.3756\nSaving model with loss 1.374...\nEpoch [124/10000]: Train loss: 1.3084, Valid loss: 1.3740\nSaving model with loss 1.366...\nEpoch [125/10000]: Train loss: 1.3261, Valid loss: 1.3664\nSaving model with loss 1.360...\nEpoch [126/10000]: Train loss: 1.3446, Valid loss: 1.3604\nSaving model with loss 1.360...\nEpoch [127/10000]: Train loss: 1.3414, Valid loss: 1.3601\nSaving model with loss 1.352...\nEpoch [130/10000]: Train loss: 1.3348, Valid loss: 1.3521\nSaving model with loss 1.343...\nEpoch [131/10000]: Train loss: 1.2951, Valid loss: 1.3426\nSaving model with loss 1.341...\nEpoch [133/10000]: Train loss: 1.3071, Valid loss: 1.3415\nSaving model with loss 1.338...\nEpoch [134/10000]: Train loss: 1.3439, Valid loss: 1.3378\nSaving model with loss 1.333...\nEpoch [135/10000]: Train loss: 1.2919, Valid loss: 1.3330\nSaving model with loss 1.330...\nEpoch [136/10000]: Train loss: 1.3460, Valid loss: 1.3298\nSaving model with loss 1.322...\nEpoch [139/10000]: Train loss: 1.3078, Valid loss: 1.3219\nSaving model with loss 1.316...\nEpoch [140/10000]: Train loss: 1.3050, Valid loss: 1.3158\nSaving model with loss 1.311...\nEpoch [141/10000]: Train loss: 1.2623, Valid loss: 1.3113\nSaving model with loss 1.307...\nEpoch [142/10000]: Train loss: 1.2923, Valid loss: 1.3068\nSaving model with loss 1.305...\nEpoch [143/10000]: Train loss: 1.2693, Valid loss: 1.3049\nSaving model with loss 1.304...\nEpoch [144/10000]: Train loss: 1.2683, Valid loss: 1.3036\nSaving model with loss 1.297...\nEpoch [151/10000]: Train loss: 1.2243, Valid loss: 1.2968\nSaving model with loss 1.290...\nEpoch [152/10000]: Train loss: 1.2942, Valid loss: 1.2895\nSaving model with loss 1.287...\nEpoch [153/10000]: Train loss: 1.3189, Valid loss: 1.2874\nSaving model with loss 1.286...\nEpoch [154/10000]: Train loss: 1.3233, Valid loss: 1.2858\nSaving model with loss 1.283...\nEpoch [155/10000]: Train loss: 1.2788, Valid loss: 1.2832\nSaving model with loss 1.282...\nEpoch [163/10000]: Train loss: 1.2438, Valid loss: 1.2823\nSaving model with loss 1.267...\nEpoch [164/10000]: Train loss: 1.2946, Valid loss: 1.2665\nSaving model with loss 1.266...\nEpoch [170/10000]: Train loss: 1.2678, Valid loss: 1.2659\nSaving model with loss 1.265...\nEpoch [171/10000]: Train loss: 1.2374, Valid loss: 1.2650\nSaving model with loss 1.254...\nEpoch [175/10000]: Train loss: 1.2762, Valid loss: 1.2542\nSaving model with loss 1.253...\nEpoch [177/10000]: Train loss: 1.2899, Valid loss: 1.2532\nSaving model with loss 1.253...\nEpoch [178/10000]: Train loss: 1.2497, Valid loss: 1.2526\nSaving model with loss 1.251...\nEpoch [179/10000]: Train loss: 1.2413, Valid loss: 1.2510\nSaving model with loss 1.244...\nEpoch [180/10000]: Train loss: 1.2083, Valid loss: 1.2440\nSaving model with loss 1.243...\nEpoch [185/10000]: Train loss: 1.2629, Valid loss: 1.2429\nSaving model with loss 1.242...\nEpoch [186/10000]: Train loss: 1.2839, Valid loss: 1.2415\nSaving model with loss 1.238...\nEpoch [187/10000]: Train loss: 1.2394, Valid loss: 1.2383\nSaving model with loss 1.238...\nEpoch [188/10000]: Train loss: 1.2058, Valid loss: 1.2379\nSaving model with loss 1.234...\nEpoch [192/10000]: Train loss: 1.2433, Valid loss: 1.2342\nSaving model with loss 1.234...\nEpoch [194/10000]: Train loss: 1.2723, Valid loss: 1.2339\nSaving model with loss 1.224...\nEpoch [197/10000]: Train loss: 1.2231, Valid loss: 1.2236\nSaving model with loss 1.221...\nEpoch [198/10000]: Train loss: 1.1970, Valid loss: 1.2207\nSaving model with loss 1.214...\nEpoch [206/10000]: Train loss: 1.2365, Valid loss: 1.2145\nSaving model with loss 1.213...\nEpoch [211/10000]: Train loss: 1.2398, Valid loss: 1.2126\nSaving model with loss 1.213...\nEpoch [212/10000]: Train loss: 1.1888, Valid loss: 1.2125\nSaving model with loss 1.207...\nEpoch [214/10000]: Train loss: 1.3013, Valid loss: 1.2074\nSaving model with loss 1.205...\nEpoch [215/10000]: Train loss: 1.2204, Valid loss: 1.2055\nSaving model with loss 1.201...\nEpoch [220/10000]: Train loss: 1.2342, Valid loss: 1.2015\nSaving model with loss 1.201...\nEpoch [221/10000]: Train loss: 1.2405, Valid loss: 1.2013\nSaving model with loss 1.199...\nEpoch [222/10000]: Train loss: 1.1876, Valid loss: 1.1991\nSaving model with loss 1.193...\nEpoch [223/10000]: Train loss: 1.2225, Valid loss: 1.1928\nSaving model with loss 1.182...\nEpoch [232/10000]: Train loss: 1.2023, Valid loss: 1.1818\nSaving model with loss 1.178...\nEpoch [233/10000]: Train loss: 1.1923, Valid loss: 1.1776\nSaving model with loss 1.171...\nEpoch [244/10000]: Train loss: 1.1670, Valid loss: 1.1706\nSaving model with loss 1.170...\nEpoch [250/10000]: Train loss: 1.2151, Valid loss: 1.1698\nSaving model with loss 1.169...\nEpoch [253/10000]: Train loss: 1.1574, Valid loss: 1.1694\nSaving model with loss 1.169...\nEpoch [255/10000]: Train loss: 1.1686, Valid loss: 1.1689\nSaving model with loss 1.163...\nEpoch [257/10000]: Train loss: 1.2143, Valid loss: 1.1626\nSaving model with loss 1.162...\nEpoch [259/10000]: Train loss: 1.1820, Valid loss: 1.1618\nSaving model with loss 1.160...\nEpoch [260/10000]: Train loss: 1.1817, Valid loss: 1.1597\nSaving model with loss 1.157...\nEpoch [266/10000]: Train loss: 1.2596, Valid loss: 1.1570\nSaving model with loss 1.154...\nEpoch [271/10000]: Train loss: 1.2893, Valid loss: 1.1537\nSaving model with loss 1.150...\nEpoch [277/10000]: Train loss: 1.1915, Valid loss: 1.1495\nSaving model with loss 1.148...\nEpoch [279/10000]: Train loss: 1.1517, Valid loss: 1.1483\nSaving model with loss 1.146...\nEpoch [281/10000]: Train loss: 1.1689, Valid loss: 1.1456\nSaving model with loss 1.142...\nEpoch [286/10000]: Train loss: 1.2216, Valid loss: 1.1418\nSaving model with loss 1.140...\nEpoch [287/10000]: Train loss: 1.1648, Valid loss: 1.1402\nSaving model with loss 1.134...\nEpoch [288/10000]: Train loss: 1.2007, Valid loss: 1.1342\nSaving model with loss 1.133...\nEpoch [289/10000]: Train loss: 1.2056, Valid loss: 1.1328\nSaving model with loss 1.132...\nEpoch [290/10000]: Train loss: 1.1540, Valid loss: 1.1321\nSaving model with loss 1.130...\nEpoch [301/10000]: Train loss: 1.1903, Valid loss: 1.1304\nSaving model with loss 1.128...\nEpoch [302/10000]: Train loss: 1.1998, Valid loss: 1.1284\nSaving model with loss 1.127...\nEpoch [303/10000]: Train loss: 1.2014, Valid loss: 1.1272\nSaving model with loss 1.124...\nEpoch [307/10000]: Train loss: 1.1299, Valid loss: 1.1236\nSaving model with loss 1.121...\nEpoch [315/10000]: Train loss: 1.1588, Valid loss: 1.1211\nSaving model with loss 1.120...\nEpoch [316/10000]: Train loss: 1.1990, Valid loss: 1.1196\nSaving model with loss 1.114...\nEpoch [319/10000]: Train loss: 1.1480, Valid loss: 1.1139\nSaving model with loss 1.113...\nEpoch [320/10000]: Train loss: 1.1485, Valid loss: 1.1126\nSaving model with loss 1.111...\nEpoch [324/10000]: Train loss: 1.1452, Valid loss: 1.1109\nSaving model with loss 1.109...\nEpoch [325/10000]: Train loss: 1.1817, Valid loss: 1.1094\nSaving model with loss 1.108...\nEpoch [326/10000]: Train loss: 1.1665, Valid loss: 1.1082\nSaving model with loss 1.105...\nEpoch [327/10000]: Train loss: 1.1551, Valid loss: 1.1048\nSaving model with loss 1.104...\nEpoch [343/10000]: Train loss: 1.1570, Valid loss: 1.1038\nSaving model with loss 1.103...\nEpoch [344/10000]: Train loss: 1.1479, Valid loss: 1.1027\nSaving model with loss 1.098...\nEpoch [347/10000]: Train loss: 1.1632, Valid loss: 1.0979\nSaving model with loss 1.097...\nEpoch [350/10000]: Train loss: 1.1481, Valid loss: 1.0966\nSaving model with loss 1.096...\nEpoch [351/10000]: Train loss: 1.1503, Valid loss: 1.0959\nSaving model with loss 1.096...\nEpoch [352/10000]: Train loss: 1.2307, Valid loss: 1.0958\nSaving model with loss 1.092...\nEpoch [353/10000]: Train loss: 1.1203, Valid loss: 1.0924\nSaving model with loss 1.090...\nEpoch [354/10000]: Train loss: 1.1213, Valid loss: 1.0904\nSaving model with loss 1.087...\nEpoch [362/10000]: Train loss: 1.1562, Valid loss: 1.0867\nSaving model with loss 1.083...\nEpoch [363/10000]: Train loss: 1.1231, Valid loss: 1.0832\nSaving model with loss 1.081...\nEpoch [376/10000]: Train loss: 1.1910, Valid loss: 1.0806\nSaving model with loss 1.080...\nEpoch [377/10000]: Train loss: 1.1125, Valid loss: 1.0799\nSaving model with loss 1.078...\nEpoch [379/10000]: Train loss: 1.1676, Valid loss: 1.0777\nSaving model with loss 1.074...\nEpoch [380/10000]: Train loss: 1.1662, Valid loss: 1.0741\nSaving model with loss 1.074...\nEpoch [391/10000]: Train loss: 1.1360, Valid loss: 1.0735\nSaving model with loss 1.072...\nEpoch [392/10000]: Train loss: 1.1279, Valid loss: 1.0720\nSaving model with loss 1.070...\nEpoch [396/10000]: Train loss: 1.1237, Valid loss: 1.0704\nSaving model with loss 1.068...\nEpoch [399/10000]: Train loss: 1.1944, Valid loss: 1.0675\nSaving model with loss 1.064...\nEpoch [401/10000]: Train loss: 1.1288, Valid loss: 1.0635\nSaving model with loss 1.062...\nEpoch [407/10000]: Train loss: 1.1222, Valid loss: 1.0616\nSaving model with loss 1.061...\nEpoch [409/10000]: Train loss: 1.1378, Valid loss: 1.0614\nSaving model with loss 1.061...\nEpoch [410/10000]: Train loss: 1.1065, Valid loss: 1.0610\nSaving model with loss 1.058...\nEpoch [415/10000]: Train loss: 1.0981, Valid loss: 1.0579\nSaving model with loss 1.058...\nEpoch [417/10000]: Train loss: 1.1017, Valid loss: 1.0579\nSaving model with loss 1.058...\nEpoch [421/10000]: Train loss: 1.1030, Valid loss: 1.0576\nSaving model with loss 1.054...\nEpoch [422/10000]: Train loss: 1.1294, Valid loss: 1.0538\nSaving model with loss 1.051...\nEpoch [432/10000]: Train loss: 1.1775, Valid loss: 1.0505\nSaving model with loss 1.047...\nEpoch [433/10000]: Train loss: 1.1182, Valid loss: 1.0474\nSaving model with loss 1.047...\nEpoch [434/10000]: Train loss: 1.2006, Valid loss: 1.0472\nSaving model with loss 1.047...\nEpoch [446/10000]: Train loss: 1.0919, Valid loss: 1.0467\nSaving model with loss 1.046...\nEpoch [448/10000]: Train loss: 1.1140, Valid loss: 1.0458\nSaving model with loss 1.040...\nEpoch [452/10000]: Train loss: 1.0976, Valid loss: 1.0395\nSaving model with loss 1.038...\nEpoch [457/10000]: Train loss: 1.1183, Valid loss: 1.0383\nSaving model with loss 1.036...\nEpoch [463/10000]: Train loss: 1.1659, Valid loss: 1.0364\nSaving model with loss 1.036...\nEpoch [464/10000]: Train loss: 1.1147, Valid loss: 1.0363\nSaving model with loss 1.036...\nEpoch [467/10000]: Train loss: 1.1138, Valid loss: 1.0356\nSaving model with loss 1.030...\nEpoch [470/10000]: Train loss: 1.0624, Valid loss: 1.0298\nSaving model with loss 1.027...\nEpoch [486/10000]: Train loss: 1.1203, Valid loss: 1.0275\nSaving model with loss 1.025...\nEpoch [488/10000]: Train loss: 1.1245, Valid loss: 1.0253\nSaving model with loss 1.024...\nEpoch [489/10000]: Train loss: 1.0787, Valid loss: 1.0244\nSaving model with loss 1.022...\nEpoch [491/10000]: Train loss: 1.0641, Valid loss: 1.0223\nSaving model with loss 1.020...\nEpoch [493/10000]: Train loss: 1.1177, Valid loss: 1.0205\nSaving model with loss 1.018...\nEpoch [495/10000]: Train loss: 1.0772, Valid loss: 1.0179\nSaving model with loss 1.015...\nEpoch [504/10000]: Train loss: 1.1190, Valid loss: 1.0147\nSaving model with loss 1.013...\nEpoch [507/10000]: Train loss: 1.0572, Valid loss: 1.0127\nSaving model with loss 1.011...\nEpoch [517/10000]: Train loss: 1.0462, Valid loss: 1.0110\nSaving model with loss 1.010...\nEpoch [518/10000]: Train loss: 1.0583, Valid loss: 1.0095\nSaving model with loss 1.008...\nEpoch [524/10000]: Train loss: 1.1172, Valid loss: 1.0082\nSaving model with loss 1.006...\nEpoch [536/10000]: Train loss: 1.0426, Valid loss: 1.0055\nSaving model with loss 1.000...\nEpoch [537/10000]: Train loss: 1.0854, Valid loss: 1.0005\nSaving model with loss 1.000...\nEpoch [555/10000]: Train loss: 1.1781, Valid loss: 0.9997\nSaving model with loss 0.994...\nEpoch [558/10000]: Train loss: 1.0947, Valid loss: 0.9938\nSaving model with loss 0.993...\nEpoch [560/10000]: Train loss: 1.1063, Valid loss: 0.9932\nSaving model with loss 0.992...\nEpoch [568/10000]: Train loss: 1.0853, Valid loss: 0.9917\nSaving model with loss 0.987...\nEpoch [570/10000]: Train loss: 1.1139, Valid loss: 0.9869\nSaving model with loss 0.984...\nEpoch [590/10000]: Train loss: 1.1274, Valid loss: 0.9840\nSaving model with loss 0.983...\nEpoch [591/10000]: Train loss: 1.0719, Valid loss: 0.9833\nSaving model with loss 0.981...\nEpoch [594/10000]: Train loss: 1.0345, Valid loss: 0.9813\nSaving model with loss 0.981...\nEpoch [600/10000]: Train loss: 1.0433, Valid loss: 0.9807\nSaving model with loss 0.980...\nEpoch [602/10000]: Train loss: 1.0453, Valid loss: 0.9795\nSaving model with loss 0.978...\nEpoch [606/10000]: Train loss: 1.0389, Valid loss: 0.9783\nSaving model with loss 0.977...\nEpoch [611/10000]: Train loss: 1.0370, Valid loss: 0.9769\nSaving model with loss 0.976...\nEpoch [619/10000]: Train loss: 1.0882, Valid loss: 0.9755\nSaving model with loss 0.975...\nEpoch [624/10000]: Train loss: 1.0536, Valid loss: 0.9749\nSaving model with loss 0.973...\nEpoch [628/10000]: Train loss: 1.0303, Valid loss: 0.9727\nSaving model with loss 0.969...\nEpoch [634/10000]: Train loss: 1.0950, Valid loss: 0.9694\nSaving model with loss 0.969...\nEpoch [645/10000]: Train loss: 1.0599, Valid loss: 0.9686\nSaving model with loss 0.966...\nEpoch [652/10000]: Train loss: 1.0638, Valid loss: 0.9660\nSaving model with loss 0.965...\nEpoch [654/10000]: Train loss: 1.0649, Valid loss: 0.9647\nSaving model with loss 0.961...\nEpoch [655/10000]: Train loss: 1.0404, Valid loss: 0.9611\nSaving model with loss 0.959...\nEpoch [669/10000]: Train loss: 1.0302, Valid loss: 0.9593\nSaving model with loss 0.957...\nEpoch [679/10000]: Train loss: 1.0240, Valid loss: 0.9565\nSaving model with loss 0.956...\nEpoch [685/10000]: Train loss: 1.0126, Valid loss: 0.9558\nSaving model with loss 0.954...\nEpoch [689/10000]: Train loss: 1.0360, Valid loss: 0.9544\nSaving model with loss 0.952...\nEpoch [700/10000]: Train loss: 1.0410, Valid loss: 0.9516\nSaving model with loss 0.950...\nEpoch [708/10000]: Train loss: 1.0524, Valid loss: 0.9503\nSaving model with loss 0.947...\nEpoch [714/10000]: Train loss: 1.0271, Valid loss: 0.9470\nSaving model with loss 0.946...\nEpoch [715/10000]: Train loss: 1.0302, Valid loss: 0.9455\nSaving model with loss 0.941...\nEpoch [723/10000]: Train loss: 1.0437, Valid loss: 0.9406\nSaving model with loss 0.940...\nEpoch [744/10000]: Train loss: 1.0721, Valid loss: 0.9404\nSaving model with loss 0.939...\nEpoch [746/10000]: Train loss: 1.0135, Valid loss: 0.9391\nSaving model with loss 0.938...\nEpoch [748/10000]: Train loss: 1.0354, Valid loss: 0.9381\nSaving model with loss 0.936...\nEpoch [750/10000]: Train loss: 1.0213, Valid loss: 0.9360\nSaving model with loss 0.936...\nEpoch [758/10000]: Train loss: 1.0340, Valid loss: 0.9360\nSaving model with loss 0.933...\nEpoch [760/10000]: Train loss: 1.0421, Valid loss: 0.9330\nSaving model with loss 0.931...\nEpoch [767/10000]: Train loss: 1.0495, Valid loss: 0.9313\nSaving model with loss 0.930...\nEpoch [768/10000]: Train loss: 0.9917, Valid loss: 0.9301\nSaving model with loss 0.930...\nEpoch [777/10000]: Train loss: 1.0255, Valid loss: 0.9299\nSaving model with loss 0.929...\nEpoch [785/10000]: Train loss: 1.0198, Valid loss: 0.9293\nSaving model with loss 0.928...\nEpoch [791/10000]: Train loss: 1.0320, Valid loss: 0.9282\nSaving model with loss 0.927...\nEpoch [792/10000]: Train loss: 0.9978, Valid loss: 0.9269\nSaving model with loss 0.926...\nEpoch [803/10000]: Train loss: 1.0037, Valid loss: 0.9257\nSaving model with loss 0.925...\nEpoch [804/10000]: Train loss: 1.0017, Valid loss: 0.9253\nSaving model with loss 0.925...\nEpoch [817/10000]: Train loss: 1.0131, Valid loss: 0.9246\nSaving model with loss 0.924...\nEpoch [820/10000]: Train loss: 1.0305, Valid loss: 0.9244\nSaving model with loss 0.922...\nEpoch [821/10000]: Train loss: 0.9959, Valid loss: 0.9221\nSaving model with loss 0.920...\nEpoch [822/10000]: Train loss: 0.9851, Valid loss: 0.9203\nSaving model with loss 0.918...\nEpoch [834/10000]: Train loss: 1.0020, Valid loss: 0.9175\nSaving model with loss 0.914...\nEpoch [851/10000]: Train loss: 1.0555, Valid loss: 0.9138\nSaving model with loss 0.912...\nEpoch [879/10000]: Train loss: 1.0197, Valid loss: 0.9116\nSaving model with loss 0.910...\nEpoch [882/10000]: Train loss: 1.0083, Valid loss: 0.9101\nSaving model with loss 0.909...\nEpoch [890/10000]: Train loss: 1.0090, Valid loss: 0.9095\nSaving model with loss 0.909...\nEpoch [902/10000]: Train loss: 1.0082, Valid loss: 0.9094\nSaving model with loss 0.908...\nEpoch [903/10000]: Train loss: 1.0346, Valid loss: 0.9076\nSaving model with loss 0.908...\nEpoch [917/10000]: Train loss: 1.0147, Valid loss: 0.9075\nSaving model with loss 0.907...\nEpoch [919/10000]: Train loss: 1.0009, Valid loss: 0.9071\nSaving model with loss 0.906...\nEpoch [920/10000]: Train loss: 1.0114, Valid loss: 0.9057\nSaving model with loss 0.905...\nEpoch [922/10000]: Train loss: 0.9946, Valid loss: 0.9050\nSaving model with loss 0.904...\nEpoch [924/10000]: Train loss: 1.0031, Valid loss: 0.9043\nSaving model with loss 0.903...\nEpoch [929/10000]: Train loss: 0.9716, Valid loss: 0.9033\nSaving model with loss 0.900...\nEpoch [939/10000]: Train loss: 1.0002, Valid loss: 0.9005\nSaving model with loss 0.899...\nEpoch [962/10000]: Train loss: 1.0236, Valid loss: 0.8988\nSaving model with loss 0.896...\nEpoch [966/10000]: Train loss: 1.0265, Valid loss: 0.8965\nSaving model with loss 0.896...\nEpoch [969/10000]: Train loss: 0.9896, Valid loss: 0.8955\nSaving model with loss 0.894...\nEpoch [988/10000]: Train loss: 0.9922, Valid loss: 0.8941\nSaving model with loss 0.893...\nEpoch [1000/10000]: Train loss: 1.0147, Valid loss: 0.8934\nSaving model with loss 0.892...\nEpoch [1007/10000]: Train loss: 1.0036, Valid loss: 0.8916\nSaving model with loss 0.891...\nEpoch [1011/10000]: Train loss: 0.9917, Valid loss: 0.8915\nSaving model with loss 0.888...\nEpoch [1019/10000]: Train loss: 1.0191, Valid loss: 0.8876\nSaving model with loss 0.887...\nEpoch [1033/10000]: Train loss: 0.9636, Valid loss: 0.8868\nSaving model with loss 0.887...\nEpoch [1043/10000]: Train loss: 0.9701, Valid loss: 0.8866\nSaving model with loss 0.886...\nEpoch [1047/10000]: Train loss: 0.9828, Valid loss: 0.8865\nSaving model with loss 0.886...\nEpoch [1058/10000]: Train loss: 0.9488, Valid loss: 0.8863\nSaving model with loss 0.885...\nEpoch [1063/10000]: Train loss: 0.9809, Valid loss: 0.8846\nSaving model with loss 0.883...\nEpoch [1072/10000]: Train loss: 0.9725, Valid loss: 0.8833\nSaving model with loss 0.882...\nEpoch [1083/10000]: Train loss: 1.0010, Valid loss: 0.8820\nSaving model with loss 0.879...\nEpoch [1114/10000]: Train loss: 1.0103, Valid loss: 0.8788\nSaving model with loss 0.877...\nEpoch [1122/10000]: Train loss: 0.9758, Valid loss: 0.8773\nSaving model with loss 0.874...\nEpoch [1148/10000]: Train loss: 0.9994, Valid loss: 0.8744\nSaving model with loss 0.873...\nEpoch [1154/10000]: Train loss: 1.0224, Valid loss: 0.8732\nSaving model with loss 0.872...\nEpoch [1167/10000]: Train loss: 0.9542, Valid loss: 0.8719\nSaving model with loss 0.871...\nEpoch [1177/10000]: Train loss: 1.0114, Valid loss: 0.8708\nSaving model with loss 0.871...\nEpoch [1189/10000]: Train loss: 0.9511, Valid loss: 0.8707\nSaving model with loss 0.869...\nEpoch [1200/10000]: Train loss: 0.9931, Valid loss: 0.8687\nSaving model with loss 0.869...\nEpoch [1209/10000]: Train loss: 1.0146, Valid loss: 0.8687\nSaving model with loss 0.869...\nEpoch [1215/10000]: Train loss: 0.9994, Valid loss: 0.8686\nSaving model with loss 0.867...\nEpoch [1228/10000]: Train loss: 0.9692, Valid loss: 0.8667\nSaving model with loss 0.865...\nEpoch [1229/10000]: Train loss: 0.9865, Valid loss: 0.8649\nSaving model with loss 0.862...\nEpoch [1276/10000]: Train loss: 0.9659, Valid loss: 0.8625\nSaving model with loss 0.862...\nEpoch [1314/10000]: Train loss: 0.9991, Valid loss: 0.8624\nSaving model with loss 0.862...\nEpoch [1334/10000]: Train loss: 0.9684, Valid loss: 0.8618\nSaving model with loss 0.860...\nEpoch [1355/10000]: Train loss: 0.9493, Valid loss: 0.8602\nSaving model with loss 0.859...\nEpoch [1366/10000]: Train loss: 0.9883, Valid loss: 0.8586\nSaving model with loss 0.858...\nEpoch [1383/10000]: Train loss: 0.9657, Valid loss: 0.8583\nSaving model with loss 0.857...\nEpoch [1396/10000]: Train loss: 0.9594, Valid loss: 0.8571\nSaving model with loss 0.857...\nEpoch [1415/10000]: Train loss: 0.9753, Valid loss: 0.8568\nSaving model with loss 0.851...\nEpoch [1428/10000]: Train loss: 0.9913, Valid loss: 0.8512\nSaving model with loss 0.850...\nEpoch [1477/10000]: Train loss: 0.9465, Valid loss: 0.8497\nSaving model with loss 0.850...\nEpoch [1509/10000]: Train loss: 0.9323, Valid loss: 0.8496\nSaving model with loss 0.847...\nEpoch [1530/10000]: Train loss: 0.9727, Valid loss: 0.8473\nSaving model with loss 0.846...\nEpoch [1567/10000]: Train loss: 0.9939, Valid loss: 0.8463\nSaving model with loss 0.846...\nEpoch [1625/10000]: Train loss: 0.9462, Valid loss: 0.8456\nSaving model with loss 0.841...\nEpoch [1634/10000]: Train loss: 0.9527, Valid loss: 0.8408\nSaving model with loss 0.841...\nEpoch [1726/10000]: Train loss: 0.9748, Valid loss: 0.8408\nSaving model with loss 0.840...\nEpoch [1735/10000]: Train loss: 1.0004, Valid loss: 0.8404\nSaving model with loss 0.839...\nEpoch [1749/10000]: Train loss: 0.9537, Valid loss: 0.8395\nSaving model with loss 0.839...\nEpoch [1804/10000]: Train loss: 0.9525, Valid loss: 0.8393\nSaving model with loss 0.839...\nEpoch [1807/10000]: Train loss: 0.9978, Valid loss: 0.8391\nSaving model with loss 0.838...\nEpoch [1828/10000]: Train loss: 0.9820, Valid loss: 0.8383\nSaving model with loss 0.838...\nEpoch [1830/10000]: Train loss: 0.9453, Valid loss: 0.8383\nSaving model with loss 0.837...\nEpoch [1834/10000]: Train loss: 0.9804, Valid loss: 0.8374\nSaving model with loss 0.836...\nEpoch [1862/10000]: Train loss: 0.9208, Valid loss: 0.8363\nSaving model with loss 0.836...\nEpoch [1863/10000]: Train loss: 0.9381, Valid loss: 0.8361\nSaving model with loss 0.836...\nEpoch [1896/10000]: Train loss: 0.9296, Valid loss: 0.8360\nSaving model with loss 0.836...\nEpoch [1906/10000]: Train loss: 0.9796, Valid loss: 0.8358\nSaving model with loss 0.834...\nEpoch [1911/10000]: Train loss: 0.9753, Valid loss: 0.8337\nSaving model with loss 0.832...\nEpoch [1947/10000]: Train loss: 0.9803, Valid loss: 0.8316\nSaving model with loss 0.830...\nEpoch [2118/10000]: Train loss: 0.9550, Valid loss: 0.8304\nSaving model with loss 0.830...\nEpoch [2179/10000]: Train loss: 0.9557, Valid loss: 0.8298\nSaving model with loss 0.828...\nEpoch [2183/10000]: Train loss: 0.9369, Valid loss: 0.8277\nSaving model with loss 0.827...\nEpoch [2239/10000]: Train loss: 0.9560, Valid loss: 0.8266\nSaving model with loss 0.826...\nEpoch [2306/10000]: Train loss: 0.9504, Valid loss: 0.8262\nSaving model with loss 0.824...\nEpoch [2315/10000]: Train loss: 0.9524, Valid loss: 0.8243\nSaving model with loss 0.823...\nEpoch [2337/10000]: Train loss: 0.9238, Valid loss: 0.8233\nSaving model with loss 0.822...\nEpoch [2423/10000]: Train loss: 0.9439, Valid loss: 0.8224\nSaving model with loss 0.821...\nEpoch [2607/10000]: Train loss: 0.9620, Valid loss: 0.8213\nSaving model with loss 0.820...\nEpoch [2704/10000]: Train loss: 0.9547, Valid loss: 0.8203\nSaving model with loss 0.819...\nEpoch [2713/10000]: Train loss: 0.9064, Valid loss: 0.8193\nSaving model with loss 0.818...\nEpoch [2823/10000]: Train loss: 0.9447, Valid loss: 0.8184\nSaving model with loss 0.818...\nEpoch [2874/10000]: Train loss: 0.9705, Valid loss: 0.8182\nSaving model with loss 0.818...\nEpoch [2881/10000]: Train loss: 0.9857, Valid loss: 0.8181\nSaving model with loss 0.818...\nEpoch [2906/10000]: Train loss: 0.9521, Valid loss: 0.8176\nSaving model with loss 0.816...\nEpoch [2981/10000]: Train loss: 0.9339, Valid loss: 0.8165\nSaving model with loss 0.816...\nEpoch [3102/10000]: Train loss: 0.9435, Valid loss: 0.8156\nSaving model with loss 0.815...\nEpoch [3422/10000]: Train loss: 0.9313, Valid loss: 0.8148\nSaving model with loss 0.815...\nEpoch [3440/10000]: Train loss: 0.9248, Valid loss: 0.8146\nSaving model with loss 0.814...\nEpoch [3556/10000]: Train loss: 0.9188, Valid loss: 0.8137\nSaving model with loss 0.814...\nEpoch [3648/10000]: Train loss: 0.9128, Valid loss: 0.8136\nSaving model with loss 0.813...\nEpoch [3656/10000]: Train loss: 0.9336, Valid loss: 0.8133\nSaving model with loss 0.813...\nEpoch [3691/10000]: Train loss: 0.9242, Valid loss: 0.8131\nSaving model with loss 0.813...\nEpoch [3814/10000]: Train loss: 0.9664, Valid loss: 0.8128\nSaving model with loss 0.813...\nEpoch [3840/10000]: Train loss: 0.9311, Valid loss: 0.8126\nSaving model with loss 0.811...\nEpoch [3847/10000]: Train loss: 0.9902, Valid loss: 0.8115\nSaving model with loss 0.810...\nEpoch [4194/10000]: Train loss: 0.9127, Valid loss: 0.8100\nSaving model with loss 0.809...\nEpoch [4195/10000]: Train loss: 0.9398, Valid loss: 0.8091\nSaving model with loss 0.808...\nEpoch [4560/10000]: Train loss: 0.9267, Valid loss: 0.8083\nSaving model with loss 0.806...\nEpoch [4736/10000]: Train loss: 0.9174, Valid loss: 0.8064\nSaving model with loss 0.806...\nEpoch [5289/10000]: Train loss: 0.8815, Valid loss: 0.8056\nSaving model with loss 0.804...\nEpoch [5325/10000]: Train loss: 0.9404, Valid loss: 0.8041\nSaving model with loss 0.804...\nEpoch [5786/10000]: Train loss: 0.9545, Valid loss: 0.8035\nSaving model with loss 0.803...\nEpoch [5802/10000]: Train loss: 0.9243, Valid loss: 0.8028\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Testing\nThe predictions of your model on testing set will be stored at `pred.csv`.","metadata":{"id":"yhAHGqC9-woK"}},{"cell_type":"code","source":"def save_pred(preds, file):\n    ''' Save predictions to specified file '''\n    with open(file, 'w') as fp:\n        writer = csv.writer(fp)\n        writer.writerow(['id', 'tested_positive'])\n        for i, p in enumerate(preds):\n            writer.writerow([i, p])\n\nmodel = My_Model(input_dim=x_train.shape[1]).to(device)\nmodel.load_state_dict(torch.load(config['save_path']))\npreds = predict(test_loader, model, device) \nsave_pred(preds, 'pred.csv')         ","metadata":{"id":"Q5eVdpbvAlAe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Download\n\nRun this block to download the `pred.csv` by clicking.","metadata":{"id":"T_N-wBvVahc7"}},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'pred.csv')","metadata":{"id":"PmMnwrHeavJv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reference\nThis notebook uses code written by Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)","metadata":{"id":"IJ_k5rY0GvSV"}}]}
